这份文档不仅是产品设计书，更是一份**“反平庸算法宣言”**。它记录了从“对现有信息流的不满”到“利用LLM重构认知体验”的完整思维推演。

---

# Project MindSlot: 核心理念与设计纲领 (v1.0)

**日期：** 2025-12-08
**核心目标：** 构建一个基于LLM原生生成的、高信噪比、能够引发“心流”体验的无限信息流系统。

---

## 1. 核心痛点与立项动机 (The "Why")

### 1.1 现有产品的失效
* **信息密度过低：** 抖音/知乎等平台为了迎合大众，将内容无限稀释。对于高认知能力用户（如资深架构师），这种内容是“时间黑洞”，只有消耗没有收益。
* **推荐算法的逆向淘汰：** 深度内容因受众小、完播率低被算法降权；博主因无激励而停止更新，导致“精英内容荒漠”。
* **表达方式的陈旧：** 即使内容有价值，人类博主的讲述方式往往枯燥、拖沓或带有令人反感的“爹味”。
* **审美疲劳（腻）：** 同质化严重，缺乏惊喜感。

### 1.2 我们的愿景
* **拒绝平庸：** 系统只服务于高认知需求，不向下兼容。
* **拒绝人类创作瓶颈：** 彻底去除“人类博主”这一中间环节，由 LLM 直接充当创作者，解决产量和风格多样性问题。
* **娱乐与深度的统一：** 用“整活”的外壳包装“硬核”的知识，在多巴胺（爽感）和内啡肽（成就感）之间寻找动态平衡。

---

## 2. 核心心理学机制 (The Mechanics)

### 2.1 斯金纳箱 (The Skinner Box)
这是用户“上瘾”且不感到枯燥的动力源。系统必须提供**间歇性变量奖励 (Intermittent Variable Rewards)**：
* **不确定性：** 下一张卡片是让人捧腹大笑的段子？还是一张极具冲击力的架构图？还是一个反直觉的历史冷知识？用户永远猜不到。
* **奖励类型多样化：**
    * **High Entropy (高整活)：** 荒诞、反差萌、毒舌吐槽。
    * **Epiphany (顿悟)：** 极简的洞见，一句话点破本质。
    * **Visual Stimuli (视觉)：** 动态图表、3D场景。

### 2.2 心流通道 (Flow & ZPD)
* **动态难度匹配：** 避免“太简单（无聊）”和“太难（焦虑）”。
* **螺旋上升：** 基于用户已有的知识图谱，推荐“刚好高出一点点”的内容，或对同一知识点进行跨学科的侧面切入（如用经济学解释Java并发）。

---

## 3. 内容生产策略 (Content Strategy)

### 3.1 LLM = 导演 + 演员 (Director-Actor Model)
* **Director (导演 Agent)：** 不生产内容，只负责编排。根据用户当前的情绪和疲劳度，决定下一张卡的题材、风格和载体。
* **Actor (演员 Agent)：** 执行导演指令，极度强化**“人设”**。
    * *必须杜绝 AI 味（教科书语气）。*
    * *预设人设：* 毒舌技术专家、赛博疯子、极简主义者、阴谋论历史学家。

### 3.2 呈现形式：图文并茂 (Beyond Text)
* **去纯文本化：** 必须利用 LLM 的多模态能力或代码生成能力。
* **DSL 渲染：** LLM 输出结构化数据（Mermaid, SVG, React Props），由前端实时渲染。
    * *例：* 不是用文字描述“死锁”，而是直接渲染一个两个红点互相卡住的动态图。

---

## 4. 推荐与记忆系统 (Recommendation Engine)

这是系统的核心护城河，分为三层记忆结构：

### 4.1 短期记忆 (Session - 30分钟)
* **目的：** 节奏控制 (Pacing) 与防撞车。
* **逻辑：** 如果刚推了深度内容，强制插入轻松内容；如果用户秒滑某个话题，本局不再出现。

### 4.2 中期记忆 (Interest Drift - 7~30天)
* **目的：** 捕捉阶段性痴迷。
* **逻辑：** 识别用户最近突然对“键盘政治”或“3D打印”感兴趣，临时提高该 Tag 的权重。

### 4.3 长期记忆 (Persona - 永久)
* **目的：** 基准线与底层偏好。
* **逻辑：** 基于显式画像（Java, 北航, 甚至孩子七个月大的育儿焦虑）和隐式向量（历史点赞内容的 Embedding 聚类）。

---

## 5. 架构设计原则 (Architecture Principles)

### 5.1 异步生产，实时消费 (Async Factory)
* **否定：** 绝不让用户等待 LLM 的实时生成（Latency 太高）。
* **肯定：** 后台作为“内容工厂”，预先生成海量“蓝本 (Blueprints)”。
* **库存逻辑：** 维护 `User Buffer Queue`，用户消耗的是库存。

### 5.2 蓝本 + 变体 (Blueprint + Variant)
* **内容复用：** 核心知识点（蓝本）只生成一次。
* **实时微调：** 在分发给具体用户时，可根据用户画像进行轻量级改写（如：“把这个Java知识点用二次元语气讲出来”）。

### 5.3 轻量级 MVP
* **后端：** Python (Flask/FastAPI) —— 迭代快，AI 生态好。
* **前端：** React (Web移动端) —— 组件化渲染方便。
* **初期数据：** 不依赖外部实时抓取，先榨干 LLM 内部的知识库（训练数据）。

---

**一句话总结：**
我们要做的不是一个“更好的百科全书”，而是一个**“能够洞察你认知G点，并用最不无聊的方式持续刺激你的 AI 脑力老虎机”**。
